ğŸŒŸ Senthera â€“ Multimodal Mental Wellness AI Assistant
Mini Project â€“ Artificial Intelligence and Machine Learning

Jawaharlal Nehru National College of Engineering (JNNCE)
Shimoga â€“ 577201

ğŸ‘¨â€ğŸ’» Team Members

Shreya R Chittaragi

Devika N D

Jagadeesh R S

ğŸ“ Guide

Dr. Chetan K R
Department of CSE, JNNCE, Shimoga

ğŸ§  Project Overview

Senthera is an intelligent multimodal mental wellness assistant capable of understanding human emotions through:

Text

Voice

Video (facial expressions)

It uses state-of-the-art AI models for:

Speech-to-text (Whisper)

Emotion detection from text (DistilBERT)

Emotion detection from voice (Wav2Vec2)

Face emotion detection (Vision Transformer)

Conversation generation (Gemini 2.5 Flash)

Senthera provides warm, empathetic, real-time responses and supports natural communication.

ğŸš€ Key Features
ğŸ”¹ 1. Text Emotion Analysis

Uses DistilBERT-based emotion classifier

Detects joy, sadness, anger, love, fear, and more

ğŸ”¹ 2. Voice Emotion Analysis

Wav2Vec2 Speech Emotion Recognition

Detects tone, stress, energy, excitement

ğŸ”¹ 3. Whisper / Faster-Whisper Speech-to-Text

Live streaming transcription

Silence detection

Handles background noise

ğŸ”¹ 4. Face Emotion Recognition

ViT model for detecting facial expressions

Works with images and video streams

ğŸ”¹ 5. Multimodal Emotion Fusion

Combines text emotion Ã— voice emotion
to get the most accurate emotional state

ğŸ”¹ 6. Gemini-based Response Generation

Gemini 2.5 Flash

Empathetic tone

Context-aware conversation

ğŸ”¹ 7. Google OAuth Login

Secure authentication

Session memory

No password stored locally

ğŸ”¹ 8. Full Frontend + Backend Integration

Flask backend

React.js frontend

Real-time communication

ğŸ“ Project Structure
senthera/
â”‚
â”œâ”€â”€ Senthera-backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ gemini_models.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ .gitignore
â”‚
â””â”€â”€ Senthera-frontend/
    â”œâ”€â”€ public/
    â”œâ”€â”€ src/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ package-lock.json
    â”œâ”€â”€ README.md
    â””â”€â”€ .gitignore

ğŸ›  Backend Setup (Flask)
1ï¸âƒ£ Create virtual environment
python -m venv .venv

2ï¸âƒ£ Activate environment

Windows:

.venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Create .env file
FLASK_SECRET=your_secret_key
GOOGLE_CLIENT_ID=your_google_client_id
GOOGLE_CLIENT_SECRET=your_google_client_secret
GEMINI_API_KEY=your_gemini_api_key

5ï¸âƒ£ Run backend
python app.py

ğŸ–¥ï¸ Frontend Setup (React)
1ï¸âƒ£ Install dependencies
npm install

2ï¸âƒ£ Start development server
npm start


Frontend URL:

http://localhost:3000/

ğŸ§© Environment Variables
Variable	Description
FLASK_SECRET	Flask app secret key
GOOGLE_CLIENT_ID	Google OAuth client ID
GOOGLE_CLIENT_SECRET	Google OAuth client secret
GEMINI_API_KEY	Gemini model API key

âš ï¸ Note: .env should NOT be uploaded to GitHub
(Already ignored via .gitignore)

ğŸ§° Tech Stack
Backend

Python

Flask

Whisper / Faster-Whisper

HuggingFace Transformers

Wav2Vec2 SER

ViT Face Emotion Model

Google Gemini 2.5 Flash

SQLite

OAuth2

Frontend

React.js

JavaScript

HTML/CSS

Webcam API

Fetch API

ğŸ¯ Project Objectives

Build an emotionally-aware AI assistant

Perform multimodal emotion recognition

Support mental wellness through empathetic dialogue

Provide real-time text, voice, and video analysis

Create a user-friendly full-stack application

ğŸš§ Future Enhancements

Combined face + voice + text emotion fusion

Real-time emotion graphs

Authentication with JWT

Mobile app (React Native / Flutter)

Full deployment (Render, Railway, Vercel)

Long-term mood tracking

âš–ï¸ License

MIT License
Recommended for academic projects & open-source contributions.

ğŸ‘¨â€ğŸ« Developed Under the Guidance Of

Dr. Chetan K R
Department of Computer Science & Engineering
JNNCE, Shimoga â€“ 577201

â¤ï¸ Developed By
Shreya R Chittaragi
Devika N D
Jagadeesh R S
